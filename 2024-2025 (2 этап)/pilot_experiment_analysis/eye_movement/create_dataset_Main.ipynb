{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объявление функций оперирующих с df\n",
    "def add_valence_word(x):\n",
    "    if x == 0:\n",
    "        return 'neutral'\n",
    "    elif x == 1:\n",
    "        return 'negative'\n",
    "    elif x == 2:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def add_veracity_word(x):\n",
    "    if x == 1:\n",
    "        return 'true'\n",
    "    elif x == 2:\n",
    "        return 'false'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def add_iat_results2(x):\n",
    "    if x>=0:\n",
    "        return 'positive'\n",
    "    elif x < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def add_exp2(x):\n",
    "    if x >= 2.5:\n",
    "        return 'positive'\n",
    "    elif x < 2.5:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def add_CB(row, column, match_values=('negative', 'positive'), mode=2):\n",
    "    valence = row['Valence']\n",
    "    result = row[column]\n",
    "    \n",
    "    if valence == 0:\n",
    "        return 'neutral'\n",
    "    \n",
    "    match_map = {\n",
    "        (1, match_values[0]): 'match_negative' if mode == 4 else 'match',\n",
    "        (2, match_values[1]): 'match_positive' if mode == 4 else 'match',\n",
    "        (1, match_values[1]): 'mismatch_positive' if mode == 4 else 'mismatch',\n",
    "        (2, match_values[0]): 'mismatch_negative' if mode == 4 else 'mismatch'\n",
    "    }\n",
    "    \n",
    "    return match_map.get((valence, result), None)\n",
    "\n",
    "\n",
    "def get_lists(data_path, participant, folder1, folder2):\n",
    "    # Формируем путь к директории Vac_3\n",
    "    vac_3_path = os.path.join(data_path, participant, 'Vac_3')\n",
    "    \n",
    "    # Находим единственную папку внутри Vac_3\n",
    "    subdirectories = [d for d in os.listdir(vac_3_path) if os.path.isdir(os.path.join(vac_3_path, d))]\n",
    "    if len(subdirectories) != 1:\n",
    "        raise ValueError(f\"Ожидается одна папка в {vac_3_path}, найдено {len(subdirectories)}\")\n",
    "    \n",
    "    # Получаем имя папки X\n",
    "    X = subdirectories[0]\n",
    "    \n",
    "    # Формируем путь к папке с FixationList\n",
    "    fixation_list_path = os.path.join(vac_3_path, X, 'Main', folder1, folder2)\n",
    "    \n",
    "    # Находим все CSV файлы в FixationList\n",
    "    csv_files = [os.path.join(fixation_list_path, f) for f in os.listdir(fixation_list_path) if f.endswith('.csv')]\n",
    "    \n",
    "    # Читаем все CSV файлы в список DataFrame\n",
    "    df_list = [pd.read_csv(file) for file in csv_files]\n",
    "\n",
    "    return df_list\n",
    "\n",
    "def Vac2Dataset(df, fixation_lists, saccade_lists):\n",
    "    df = df.copy()\n",
    "    # Создание списка для хранения строк\n",
    "    rows = []\n",
    "    if df.shape[0] != 111:\n",
    "        return None\n",
    "    for idx in tqdm(range(df.shape[0]), total=df.shape[0]):\n",
    "        # Получаем текущие данные Fixation и Saccade\n",
    "        fixation_df = fixation_lists[idx]\n",
    "        saccade_df = saccade_lists[idx]\n",
    "\n",
    "        # Получаем текущую строку Base_Report\n",
    "        base_row = df.iloc[[idx]].copy()  # Копируем строку как DataFrame\n",
    "\n",
    "        # Определяем количество строк в Fixation и Saccade для данного индекса\n",
    "        fixation_rows = fixation_df if not fixation_df.empty else pd.DataFrame(columns=fixation_df.columns)\n",
    "        saccade_rows = saccade_df if not saccade_df.empty else pd.DataFrame(columns=saccade_df.columns)\n",
    "\n",
    "        # Максимум строк для этого индекса\n",
    "        max_rows_local = max(len(fixation_rows), len(saccade_rows))\n",
    "\n",
    "        # Если ни Fixation, ни Saccade не имеют строк, просто добавляем строку Base_Report\n",
    "        if max_rows_local == 0:\n",
    "            rows.append(base_row)\n",
    "\n",
    "        for i in range(max_rows_local):\n",
    "            # Создаем копию строки Base_Report для каждой итерации\n",
    "            new_row = base_row.copy()\n",
    "\n",
    "            # Добавляем данные из Fixation, если они есть\n",
    "            if i < len(fixation_rows):\n",
    "                for col in fixation_df.columns:\n",
    "                    new_row[f\"f_{col}\"] = fixation_rows.iloc[i][col]\n",
    "            else:\n",
    "                for col in fixation_df.columns:\n",
    "                    new_row[f\"f_{col}\"] = None\n",
    "\n",
    "            # Добавляем данные из Saccade, если они есть\n",
    "            if i < len(saccade_rows):\n",
    "                for col in saccade_df.columns:\n",
    "                    new_row[f\"s_{col}\"] = saccade_rows.iloc[i][col]\n",
    "            else:\n",
    "                for col in saccade_df.columns:\n",
    "                    new_row[f\"s_{col}\"] = None\n",
    "\n",
    "            # Добавляем строку в список\n",
    "            rows.append(new_row)\n",
    "    [row for row in rows if row.isnull().all(axis=None) or row.empty]\n",
    "    # Конкатенируем все строки в один DataFrame\n",
    "    final_df = pd.concat(rows, ignore_index=True)\n",
    "    return final_df\n",
    "\n",
    "def find_header_row(file, expected_columns):\n",
    "    data = pd.read_csv(file, header=None)  # Читаем файл без заголовков\n",
    "    for i, row in enumerate(data.values):\n",
    "        # Проверяем, что все ожидаемые столбцы присутствуют в этой строке\n",
    "        if all(col in row for col in expected_columns):\n",
    "            return i\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_baseReport(data_path, participant):\n",
    "    # Формируем путь к директории Vac_3\n",
    "    vac_3_path = os.path.join(data_path, participant, 'Vac_3')\n",
    "    # Находим единственную папку внутри Vac_3\n",
    "    subdirectories = [d for d in os.listdir(vac_3_path) if os.path.isdir(os.path.join(vac_3_path, d))]\n",
    "    if len(subdirectories) != 1:\n",
    "        raise ValueError(f\"Ожидается одна папка в {vac_3_path}, найдено {len(subdirectories)}\")\n",
    "    # Получаем имя папки X\n",
    "    X = subdirectories[0]\n",
    "    return os.path.join(data_path, participant, 'Vac_3', X, 'BaseReport.csv')\n",
    "\n",
    "logging.basicConfig(filename='log.txt', level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s', encoding='utf-8')\n",
    "\n",
    "data_path = 'EEG_CB_IAT'\n",
    "pivot_df = pd.read_excel('CB_EEG_RSF.xlsx')\n",
    "\n",
    "columns_order = ['Row_num', 'Valence', 'Veracity', 'Performance Rate1', 'Main_ Answer', \n",
    "                'Valence_word', 'Veracity_word', 'IAT_results', 'IAT_streght','EXP_consp', 'EXP_covid', \n",
    "                'IAT_results2', 'EXP_general2', 'EXP_consp2', 'EXP_covid2', \n",
    "                'CB_IAT2', 'CB_IAT4', 'CB_EXP_general2', 'CB_EXP_general4', 'CB_EXP_covid2', 'CB_EXP_covid4', 'CB_EXP_consp2', 'CB_EXP_consp4', \n",
    "                'f_Index', 'f_Center X', 'f_Center Y', 'f_Start Time', 'f_Duration', 'f_End Time', \n",
    "                's_Index', 's_Start Time', 's_Start X', 's_Start Y', 's_Duration', 's_Amplitude', 's_Distance',\n",
    "                's_Peak Velocity', 's_Average Velocity', 's_End Time', 's_End X', 's_End Y']\n",
    "\n",
    "expected_columns = ['Row_num', 'Valence', 'Veracity', 'Performance Rate1', 'Main_ Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:11<00:00,  9.77it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB11005 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:09<00:00, 11.43it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB11006 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:11<00:00,  9.70it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB11008 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:08<00:00, 12.95it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB11010 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:10<00:00, 10.14it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB11013 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:11<00:00,  9.80it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB11014 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:10<00:00, 11.06it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB11016 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:24<00:00,  4.52it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB11020 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:12<00:00,  9.11it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB11021 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:10<00:00, 10.64it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB11025 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:16<00:00,  6.83it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB11029 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:16<00:00,  6.93it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB12002 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:11<00:00,  9.32it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB12003 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:10<00:00, 10.92it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB12007 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:11<00:00, 10.02it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB12009 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:14<00:00,  7.56it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB12011 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:07<00:00, 14.36it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB12012 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:09<00:00, 12.06it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB12015 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:12<00:00,  9.21it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB12017 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:06<00:00, 18.49it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB12018 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:15<00:00,  7.26it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB12019 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:09<00:00, 11.43it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB12023 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:08<00:00, 12.64it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB12024 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:09<00:00, 12.04it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB12026 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:15<00:00,  7.38it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB12027 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:08<00:00, 13.41it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB12028 is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:10<00:00, 11.01it/s]\n",
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14492\\3005881015.py:125: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGCB12030 is done!\n"
     ]
    }
   ],
   "source": [
    "temp_dfs_list = []\n",
    "name_list = []\n",
    "temp_avg_dfs_list = []\n",
    "for participant in os.listdir(data_path):\n",
    "    #if participant in ['EEGCB12002',]:\n",
    "    #    continue\n",
    "    baseReport_path = get_path_baseReport(data_path, participant)\n",
    "    skip_i = 8#find_header_row(baseReport_path, expected_columns)\n",
    "    df = pd.read_csv(baseReport_path, skiprows=skip_i)\n",
    "    df['Valence_word'] = df['Valence'].apply(add_valence_word)\n",
    "    df['Veracity_word'] = df['Veracity'].apply(add_veracity_word)\n",
    "    df['Main_ Answer'] = df['Main_ Answer'].replace(5, pd.NA)\n",
    "    participant_data = pivot_df[pivot_df['ID'] == participant]\n",
    "    if not participant_data.empty:\n",
    "        df['IAT_results'] = participant_data['IAT_results'].values[0]\n",
    "        df['IAT_streght'] = participant_data['IAT_streght'].values[0]\n",
    "        df['EXP_general'] = participant_data['EXP1 (general)'].values[0]\n",
    "        df['EXP_consp'] = participant_data['EXP2 (consp)'].values[0]\n",
    "        df['EXP_covid'] = participant_data['EXP3 (covid)'].values[0]\n",
    "\n",
    "    # Добавление переменных дублёров\n",
    "    df['IAT_results2'] = df['IAT_results'].apply(add_iat_results2)\n",
    "    df['EXP_general2'] = df['EXP_general'].apply(add_exp2)\n",
    "    df['EXP_consp2'] = df['EXP_consp'].apply(add_exp2)\n",
    "    df['EXP_covid2'] = df['EXP_covid'].apply(add_exp2)\n",
    "\n",
    "    # Добавление CB переменных по формулам\n",
    "    df['CB_IAT2'] = df.apply(lambda row: add_CB(row, 'IAT_results2', mode=2), axis=1)\n",
    "    df['CB_IAT4'] = df.apply(lambda row: add_CB(row, 'IAT_results2', mode=4), axis=1)\n",
    "    df['CB_EXP_general2'] = df.apply(lambda row: add_CB(row, 'EXP_general2', mode=2), axis=1)\n",
    "    df['CB_EXP_general4'] = df.apply(lambda row: add_CB(row, 'EXP_general2', mode=4), axis=1)\n",
    "    df['CB_EXP_covid2'] = df.apply(lambda row: add_CB(row, 'EXP_covid2', mode=2), axis=1)\n",
    "    df['CB_EXP_covid4'] = df.apply(lambda row: add_CB(row, 'EXP_covid2', mode=4), axis=1)\n",
    "    df['CB_EXP_consp2'] = df.apply(lambda row: add_CB(row, 'EXP_consp2', mode=2), axis=1)\n",
    "    df['CB_EXP_consp4'] = df.apply(lambda row: add_CB(row, 'EXP_consp2', mode=4), axis=1)\n",
    "\n",
    "    # Get fication lists and saccade lists\n",
    "    fix_list = get_lists(data_path, participant, 'FD_Screen', 'FixationList')\n",
    "    sd_list = get_lists(data_path, participant, 'SD_Screen', 'SaccadeList')\n",
    "\n",
    "    final_data = Vac2Dataset(df, fix_list, sd_list)\n",
    "    if final_data is None:\n",
    "        print(f'{participant} data ERROR')\n",
    "    final_data = final_data[columns_order]\n",
    "    \n",
    "    final_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    agg_funcs = {\n",
    "        'f_Duration': ['count', 'first', 'mean', 'sum'],\n",
    "        's_Duration': ['count', 'mean', 'sum'],\n",
    "        's_Amplitude': ['mean', 'sum'],\n",
    "        's_Distance': ['mean', 'sum'],\n",
    "        's_Peak Velocity': ['mean', 'sum']\n",
    "    }\n",
    "    # Агрегация по метрикам\n",
    "    metrics = final_data.groupby('Row_num').agg(agg_funcs)\n",
    "    # Переименование столбцов для удобства\n",
    "    metrics.columns = [\n",
    "        'fixation_count', 'first_FD', 'mean_FD', 'total_FD',\n",
    "        'saccades_count', 'mean_SD', 'total_SD',\n",
    "        'mean_SA', 'total_SA',\n",
    "        'mean_SDist', 'total_SDist',\n",
    "        'mean_PV', 'total_PV'\n",
    "    ]\n",
    "    # Сброс индекса, чтобы сохранить trial как столбец\n",
    "    metrics = metrics.reset_index()\n",
    "    metrics = pd.merge(df, metrics, on='Row_num', how='left')\n",
    "\n",
    "    print(f'{participant} is done!')\n",
    "    temp_dfs_list.append(final_data)\n",
    "    temp_avg_dfs_list.append(metrics)\n",
    "    name_list.append(participant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Список предобработанных участников для создания датасета: ['EEGCB11005', 'EEGCB11006', 'EEGCB11008', 'EEGCB11010', 'EEGCB11013', 'EEGCB11014', 'EEGCB11016', 'EEGCB11020', 'EEGCB11021', 'EEGCB11025', 'EEGCB11029', 'EEGCB12002', 'EEGCB12003', 'EEGCB12007', 'EEGCB12009', 'EEGCB12011', 'EEGCB12012', 'EEGCB12015', 'EEGCB12017', 'EEGCB12018', 'EEGCB12019', 'EEGCB12023', 'EEGCB12024', 'EEGCB12026', 'EEGCB12027', 'EEGCB12028', 'EEGCB12030']\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(temp_dfs_list, name_list):\n",
    "    for i, df in enumerate(temp_dfs_list):\n",
    "        df['Participant'] = os.path.splitext(name_list[i])[0]\n",
    "        cols = df.columns.tolist()\n",
    "        cols = ['Participant'] + [col for col in cols if col != 'Participant']\n",
    "        temp_dfs_list[i] = df[cols]\n",
    "\n",
    "        \n",
    "        temp_avg_dfs_list[i]['Participant'] = os.path.splitext(name_list[i])[0]\n",
    "        cols = temp_avg_dfs_list[i].columns.tolist()\n",
    "        cols = ['Participant'] + [col for col in cols if col != 'Participant']\n",
    "        temp_avg_dfs_list[i] = temp_avg_dfs_list[i][cols]\n",
    "\n",
    "    # Объединяем все таблицы в одну\n",
    "    combined_df = pd.concat(temp_dfs_list, ignore_index=True)\n",
    "    combined_metrics = pd.concat(temp_avg_dfs_list, ignore_index=True)\n",
    "    return combined_df, combined_metrics\n",
    "print(f'Список предобработанных участников для создания датасета: {name_list}')\n",
    "dataset, dataset_metrics = create_dataset(temp_dfs_list, name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_excel('EYE_RAW_MAIN.xlsx', index=False)\n",
    "dataset_metrics.to_excel('EYE_MAIN.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
